:PROPERTIES:
:ID:       a9221448-bfee-4bc6-b5d4-b1aa4db97be3
:END:
#+title: Kaggle: Intro to Machine Learning
#+filetags: :Python:MachineLearning:AI:Coding:

* How models work

[[https://www.kaggle.com/code/dansbecker/how-models-work][Kaggle]]

Models use past information to identify patterns and make similar decisions using new data.

One model is a decision tree.
These break options into relatively simplistic categories, and make decisions based on whether those categories are met.

#+ATTR_LATEX: :caption \bicaption{---} :float multicolumn
[[file:/home/csj7701/roam/Attachments/Kaggle.DecisionTree.png]]

We identify a pattern, which is represented in a decision tree.
That pattern is derived from a set of data - the process of capturing patterns from data is known as *[[id:df374b08-f412-4d81-93a5-aba39646a660][Fitting]]*, or *[[id:df374b08-f412-4d81-93a5-aba39646a660][Training]]* the model. The data used to train or fit the model is known as the *[[id:7f6fc21c-b38f-4902-a6c0-da2a7a2d6314][Training Data]]*.

After the model has been fit, you can feed new data to the model and use it to predict new results.

The decision tree shown above is limited in its use-case, since it can only represent a binary decision.
Adding more layers to the tree can help improve the number of factors that the decision tree can take into account.
These trees are called "Deeper", and contain more "Splits".

* Exploring Data

[[https://www.kaggle.com/code/dansbecker/basic-data-exploration/tutorial][Kaggle]]

Here, we read a csv file and store it in a python object known as a [[id:82ee2a61-5703-4c15-a68c-67249ae94cd7][Dataframe]]

#+begin_src python :results verbatim
  import pandas as pd
  melbourne_file_path = '/home/csj7701/roam/References/Kaggle-MelbourneHousingData.csv'
  # Read data and store in DataFrame title melbourne_data
  melbourne_data = pd.read_csv(melbourne_file_path)
  # Print a summary of the data
  table = melbourne_data.describe()
  return table
#+end_src

#+RESULTS:
#+begin_example
              Rooms         Price  ...    Longtitude  Propertycount
count  13580.000000  1.358000e+04  ...  13580.000000   13580.000000
mean       2.937997  1.075684e+06  ...    144.995216    7454.417378
std        0.955748  6.393107e+05  ...      0.103916    4378.581772
min        1.000000  8.500000e+04  ...    144.431810     249.000000
25%        2.000000  6.500000e+05  ...    144.929600    4380.000000
50%        3.000000  9.030000e+05  ...    145.000100    6555.000000
75%        3.000000  1.330000e+06  ...    145.058305   10331.000000
max       10.000000  9.000000e+06  ...    145.526350   21650.000000

[8 rows x 13 columns]
#+end_example

* Coding Exercise

We just set up a dataset that contains home data from melbourne. This will be useful to train our model, but we need to set up a /different/ data set to actually use our model (results will always be perfect if we run the model on the data we train it on - not initially intuitive, but it makes sense)

#+begin_src python :results verbatim :session ML_exercise
  import pandas as pd

  iowa_file_path = '/home/csj7701/roam/References/Kaggle-IowaHousingData.csv'
  home_data = pd.read_csv(iowa_file_path)
  iowa_table=home_data.describe()
  # Get average lot size by looking at LotArea column, then checking the "mean" row
  avg_lot_size = 10517 # Rounded to nearest Integer
  # Get age of newest home by checking YearBuilt column, and subtracting from current data
  newest_home_age = 14

  iowa_table
#+end_src

#+RESULTS:
#+begin_example
                Id   MSSubClass  LotFrontage        LotArea  OverallQual  OverallCond  ...  ScreenPorch     PoolArea       MiscVal       MoSold       YrSold      SalePrice
count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000  1460.000000  ...  1460.000000  1460.000000   1460.000000  1460.000000  1460.000000    1460.000000
mean    730.500000    56.897260    70.049958   10516.828082     6.099315     5.575342  ...    15.060959     2.758904     43.489041     6.321918  2007.815753  180921.195890
std     421.610009    42.300571    24.284752    9981.264932     1.382997     1.112799  ...    55.757415    40.177307    496.123024     2.703626     1.328095   79442.502883
min       1.000000    20.000000    21.000000    1300.000000     1.000000     1.000000  ...     0.000000     0.000000      0.000000     1.000000  2006.000000   34900.000000
25%     365.750000    20.000000    59.000000    7553.500000     5.000000     5.000000  ...     0.000000     0.000000      0.000000     5.000000  2007.000000  129975.000000
50%     730.500000    50.000000    69.000000    9478.500000     6.000000     5.000000  ...     0.000000     0.000000      0.000000     6.000000  2008.000000  163000.000000
75%    1095.250000    70.000000    80.000000   11601.500000     7.000000     6.000000  ...     0.000000     0.000000      0.000000     8.000000  2009.000000  214000.000000
max    1460.000000   190.000000   313.000000  215245.000000    10.000000     9.000000  ...   480.000000   738.000000  15500.000000    12.000000  2010.000000  755000.000000

[8 rows x 38 columns]
#+end_example

When analyaing our data, its important to consider how applicable the dataset we are using will be.
In this case, the newest house in the dataset is 14 years old. This may not be the best dataset to use, considering how old the data is. If we were constructing a model to, for instance, calculate how much a house is worth based on different factors, then this data will likely not be useful since it is largely outdated.

* First Machine Learning Model

Previously, our dataset had too many variables to actually use. They didn't even fit on my screen!
We can pare this data down, choosing a few variables based on intuition.

First, we want to see a list of all the columns in the dataset.

#+begin_src python :results verbatim :session first_model

  import pandas as pd

  melbourne_file_path = '/home/csj7701/roam/References/Kaggle-MelbourneHousingData.csv'
  melbourne_data=pd.read_csv(melbourne_file_path)
  melbourne_data.columns
  
#+end_src

#+RESULTS:
: Index(['Suburb', 'Address', 'Rooms', 'Type', 'Price', 'Method', 'SellerG',
:        'Date', 'Distance', 'Postcode', 'Bedroom2', 'Bathroom', 'Car',
:        'Landsize', 'BuildingArea', 'YearBuilt', 'CouncilArea', 'Lattitude',
:        'Longtitude', 'Regionname', 'Propertycount'],
:       dtype='object')

_Note_: Our melbourne dataset contains some missing values (rows that contain no data). We can remove these with the =dropna= function

#+begin_src python :result none :session first_model
  melbourne_data=melbourne_data.dropna(axis=0)
  melbourne_data
#+end_src

#+RESULTS:
#+begin_example
             Suburb          Address  Rooms  ... Longtitude             Regionname Propertycount
1        Abbotsford  25 Bloomburg St      2  ...  144.99340  Northern Metropolitan        4019.0
2        Abbotsford     5 Charles St      3  ...  144.99440  Northern Metropolitan        4019.0
4        Abbotsford      55a Park St      4  ...  144.99410  Northern Metropolitan        4019.0
6        Abbotsford     124 Yarra St      3  ...  144.99930  Northern Metropolitan        4019.0
7        Abbotsford    98 Charles St      2  ...  144.99540  Northern Metropolitan        4019.0
...             ...              ...    ...  ...        ...                    ...           ...
12205    Whittlesea    30 Sherwin St      3  ...  145.13282      Northern Victoria        2170.0
12206  Williamstown      75 Cecil St      3  ...  144.90474   Western Metropolitan        6380.0
12207  Williamstown    2/29 Dover Rd      1  ...  144.89936   Western Metropolitan        6380.0
12209       Windsor  201/152 Peel St      2  ...  144.99025  Southern Metropolitan        4380.0
12212    Yarraville  54 Pentland Pde      6  ...  144.89389   Western Metropolitan        6543.0

[6196 rows x 21 columns]
#+end_example

We can pull out an individual variable with [[id:9ee1538a-16ed-47b5-b602-be0a8ff9cb4a][Dot Notation]] (this is similar to C++ and other Obj. Oriented languages)
Using this dot notation stores the data in a [[id:4e40b985-2fcd-4f4b-8e53-64f33e1f5f58][Series]], which is similar to a [[id:82ee2a61-5703-4c15-a68c-67249ae94cd7][Dataframe]], but with a single column of data.
We use dot notation to select the column that we want to predict, or the [[id:6a678bf7-65b1-4460-bf49-527dbc10bbdf][Prediction Target]].
(By convention, this target is called =y=)

This means that, following the example of a model meant to predict housing prices, we should have:

#+begin_src python :results verbatim :session first_model
  y=melbourne_data.Price
  y
#+end_src

#+RESULTS:
#+begin_example
1        1035000.0
2        1465000.0
4        1600000.0
6        1876000.0
7        1636000.0
           ...    
12205     601000.0
12206    1050000.0
12207     385000.0
12209     560000.0
12212    2450000.0
Name: Price, Length: 6196, dtype: float64
#+end_example

Columns that we input into our model are known as [[id:474e981d-6b04-4447-ab74-8c7d296a9b5d][Features]].
In our case, these would be the categories that we think will affect the home's price. We can select multiple features by organizing them in an array, then saving them to a variable. The data for these features is know as =X=.

#+begin_src python :results verbatim :session first_model
  melbourne_features=['Rooms', 'Bathroom', 'Landsize', 'Lattitude', 'Longtitude']
  X=melbourne_data[melbourne_features]
  X
#+end_src

#+RESULTS:
#+begin_example
       Rooms  Bathroom  Landsize  Lattitude  Longtitude
1          2       1.0     156.0  -37.80790   144.99340
2          3       2.0     134.0  -37.80930   144.99440
4          4       1.0     120.0  -37.80720   144.99410
6          3       2.0     245.0  -37.80240   144.99930
7          2       1.0     256.0  -37.80600   144.99540
...      ...       ...       ...        ...         ...
12205      3       2.0     972.0  -37.51232   145.13282
12206      3       1.0     179.0  -37.86558   144.90474
12207      1       1.0       0.0  -37.85588   144.89936
12209      2       1.0       0.0  -37.85581   144.99025
12212      6       3.0    1087.0  -37.81038   144.89389

[6196 rows x 5 columns]
#+end_example

#+begin_src python :resulte verbatim :session first_model
  X.describe
#+end_src

#+RESULTS:
#+begin_example
<bound method NDFrame.describe of        Rooms  Bathroom  Landsize  Lattitude  Longtitude
1          2       1.0     156.0  -37.80790   144.99340
2          3       2.0     134.0  -37.80930   144.99440
4          4       1.0     120.0  -37.80720   144.99410
6          3       2.0     245.0  -37.80240   144.99930
7          2       1.0     256.0  -37.80600   144.99540
...      ...       ...       ...        ...         ...
12205      3       2.0     972.0  -37.51232   145.13282
12206      3       1.0     179.0  -37.86558   144.90474
12207      1       1.0       0.0  -37.85588   144.89936
12209      2       1.0       0.0  -37.85581   144.99025
12212      6       3.0    1087.0  -37.81038   144.89389

[6196 rows x 5 columns]>
#+end_example

#+begin_src python :results verbatim :session first_model
  X.head()
#+end_src

#+RESULTS:
:    Rooms  Bathroom  Landsize  Lattitude  Longtitude
: 1      2       1.0     156.0   -37.8079    144.9934
: 2      3       2.0     134.0   -37.8093    144.9944
: 4      4       1.0     120.0   -37.8072    144.9941
: 6      3       2.0     245.0   -37.8024    144.9993
: 7      2       1.0     256.0   -37.8060    144.9954

** Building the model

We use the =scikit-learn= library to create our models. This is written as sklearn, and is popular for modeling data stored in dataframes.

#+begin_src python :results verbatim :session first_model
  from sklearn.tree import DecisionTreeRegressor

  # Define a model. Specify a number for random_state to ensure same results each run.
  melbourne_model=DecisionTreeRegressor()

  # Fit the model
  melbourne_model.fit(X, y)
#+end_src

#+RESULTS:

Many machine learning models allow for randomness when training a model. Specifying =random_state= ensures that you get the exact same results every run.
We now have a fitted model that we can use to make predictions.

Typically, we want to make predictions for /new/ houses, coming on the market. We can use our traning data as an example for now.

#+begin_src python :results verbatim :session first_model
  melbourne_model.predict(X.head())
#+end_src

#+RESULTS:
Not currently working. Think it's an emacs issue - getting lisp errors. 
Answer should be: [1035000. 1465000. 1600000. 1876000. 1636000.]

* Coding Exercise

Previously, we added the iowa home data.
Check what columns this data set uses.
#+begin_src python :results verbatim :session ML_exercise
  home_data.columns
#+end_src

#+RESULTS:
#+begin_example
Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',
       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',
       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',
       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',
       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',
       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',
       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',
       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',
       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',
       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',
       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',
       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',
       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',
       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',
       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',
       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',
       'SaleCondition', 'SalePrice'],
      dtype='object')
#+end_example

Using these column names, we see that we want to predict the variable =SalePrice=. We can pull this variable out using [[id:9ee1538a-16ed-47b5-b602-be0a8ff9cb4a][Dot Notation]]
#+begin_src python :results verbatim :session ML_exercise
  y=home_data.SalePrice
#+end_src

#+RESULTS:
: None

Now we want to create a dataframe =X= with the features we want to evaluate the house based on.
For our purposes, these will be =LotArea=, =YearBuilt=, =1srFlrSF=, =2ndFlrSF=, =FullBath=, =BedroomAbvGr=, =TotRmsAbvGrd=
#+begin_src python :results verbatim :session ML_exercise
  feature_names=["LotArea", "YearBuilt", "1stFlrSF", "2ndFlrSF", "FullBath", "BedroomAbvGr", "TotRmsAbvGrd"]
  X=home_data[feature_names]
  X
#+end_src

#+RESULTS:
#+begin_example
      LotArea  YearBuilt  1stFlrSF  2ndFlrSF  FullBath  BedroomAbvGr  TotRmsAbvGrd
0        8450       2003       856       854         2             3             8
1        9600       1976      1262         0         2             3             6
2       11250       2001       920       866         2             3             6
3        9550       1915       961       756         1             3             7
4       14260       2000      1145      1053         2             4             9
...       ...        ...       ...       ...       ...           ...           ...
1455     7917       1999       953       694         2             3             7
1456    13175       1978      2073         0         2             3             7
1457     9042       1941      1188      1152         2             4             9
1458     9717       1950      1078         0         1             2             5
1459     9937       1965      1256         0         1             3             6

[1460 rows x 7 columns]
#+end_example

Now we can specify the model, and fit using the data.

#+begin_src python :results verbatim :session ML_exercise
  from sklearn.tree import DecisionTreeRegressor
  iowa_model=DecisionTreeRegressor(random_state=1)
  iowa_model.fit(X,y)

#+end_src

#+RESULTS:
: DecisionTreeRegressor(random_state=1)

Finally, we can make predictions
#+begin_src python :results verbatim :session ML_exercise
  predictions=iowa_model.predict(X)
  predictions
#+end_src

#+RESULTS:
: [208500. 181500. 223500. ... 266500. 142125. 147500.]

* Model Validation
Whenever we create a model, its important to /validate/ it. This is essentially an evalutation of how accurate the models predictions are; how close they come to reality.

It's important to remember not to evaluate a model based on its training data.
Checking to see how accurately a model predicts data that it was trained on is circular - it will almost always do well.

There are many ways to check a models accuracy.
One of them is known as *Mean Absolute Error* - =error=actual-predicted=
When we use this calculation, we can say that "On average, our predictions were off by about X" where X is the calculated error.

Using this in code is relatively simple:
#+begin_src python
  from sklearn.metrics import mean_absolute_error

  predicted_home_prices = melbourne_model.predict(X)
  mean_absolute_error(y, predicted_home_prices)
#+end_src

 However, in practice what we have just done is use the same sample of data for both building the model and evaluating it - this is known as 'in-sample' validation.
 Typically the best way to ensure that you get the best results when evaluating your model is to seperate a section of data before you build the model and use that as /validation data/ that is used only for error calculation.
 This is also relatively easy to automate in our code.
 #+begin_src python
   from sklearn.model_selection import train_test_split
   # This will split the data into a training section and a validation section.
   # This split is based on a random number, but supplying a numeric value will ensure that we get the same split every time we run this code.
   train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=0)
   # Define model
   melbourne_model = DecisionTreeRegressor()
   # Fit model
   melbourne_model.fit(train_X, train_y)

   # Get predicted prices on validation data
   val_predictions = melbourne_model.predict(val_X)
   print(mean_absolute_error(val_y, val_predictions))
 #+end_src

 Earlier, the in-sample calculation should have given us $434.72, whereas the /out/ of sample validation resulted in $265,806.91.
 This is the difference between a model that is almost exactly right, and one that is almost unusable for any practical purpose. 

* Coding Exercise

#+begin_src python :results value verbatim :session ML_exercise
  from sklearn.model_selection import train_test_split
  train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)

  iowa_model=DecisionTreeRegressor(random_state=1)
  iowa_model.fit(train_X, train_y)
  val_predictions=iowa_model.predict(val_X)
  predict_head=iowa_model.predict(X.head())
  actual_head=y.head().tolist()
  predict_head, actual_head
#+end_src

#+RESULTS:
: (array([208500., 181500., 223500., 128000., 250000.]), [208500, 181500, 223500, 140000, 250000])

Calculate the mean absolute error
#+begin_src python :results verbatim :session ML_exercise
  from sklearn.metrics import mean_absolute_error
  val_mae=mean_absolute_error(val_y, val_predictions)
  val_mae

#+end_src

#+RESULTS:
: 29652.931506849316

* Underfitting and Overfitting

Now that we have the ability to check how accurate a model is, we can start experimenting with different models to see which gives us better results.
The [[http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html][Sci-Kit Documentation]] lists options for the regression tree model that we have been using. One of these options allows us to specify the decision tree's /depth/ or number of splits.

As we introduce more layers, we create more "leaves", or end nodes. As we create more of these nodes, they become more granular and there are fewer results that fall into each node (For example, there will be more houses that fit into the node specifying $0-$200,000 than the more granular node that specifies $0-$5000).

If we add too many layers, we may start to see a near perfect match to the training data, but any new data will likely see poor results. This is because we have [[id:527fdb29-067d-4122-b89b-f98ec08d4ef6][Overfit]] the model.
Conversely, if the model doesn't enough layers it will be nonspecific, and while it may classify the data well into the layers it has, there aren't enough layers (not enough specificity) for this data to actually be useful. This is known as [[id:0dafc639-6812-4205-b2bd-4f0b5d57c9d0][Underfitting]].

#+ATTR_LATEX: :caption \bicaption{---}
[[file:/home/csj7701/roam/Attachments/Kaggle.Fitting.png]]

There are several ways to control the depth in python, but one of the simplest is to use the =max_leaf_nodes= variable.
We can define a utility function to help compare MAE scores from different max_node values.
#+begin_src python :results value verbatim
  from sklearn.metrics import mean_absolute_error
  from sklearn.tree import DecisionTreeRegressor

  def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):
    model=DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)
    model.fit(train_X, train_y)
    preds_val=model.predict(val_X)
    mae=mean_absolute_error(val_y, preds_val)
    return(mae)

  
  # We can use this new function with a for-loop to compare MAE values
  for max_leaf_nodes in [5, 50, 500, 5000]:
    my_mae=get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)
    print("Max leaf nodes: %d  \t\t Mean Absolute Error:  %d" %(max_leaf_nodes, my_mae))
#+end_src

#+RESULTS:
: None

* Code Exercise
Time to optimize the model that we've constructed so far. 

#+begin_src python :results verbatim :session ML_exercise
  def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):
    model=DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)
    model.fit(train_X, train_y)
    preds_val=model.predict(val_X)
    mae=mean_absolute_error(val_y, preds_val)
    return(mae)

  candidate_max_leaf_nodes=[5, 25, 50, 100, 250, 500]

  min_mae=float('inf') # initialize with positive infinity, everything will be less than this.
  min_nodes=None
  for num in candidate_max_leaf_nodes:
    mae=get_mae(num, train_X, val_X, train_y, val_y)
    print("Max nodes: %d \t\t MAE: %d" %(num, mae))
    if mae < min_mae:
      min_mae=mae
      print("less")
      min_nodes=num

  min_nodes
#+end_src

#+RESULTS:
: 100

Now we can fit the model using our optimized depth

#+begin_src python :results verbatim :session ML_exercise
  final_model=DecisionTreeRegressor(max_leaf_nodes=100, random_state=0)
  final_model.fit(X, y)
#+end_src

#+RESULTS:
: DecisionTreeRegressor(max_leaf_nodes=100, random_state=0)

* Random Forests

Decision trees involve some difficult decisions. Going to deep can quickly overfit our model, and too shallow can underfit.

Several models use clever implementation to achieve better performance. One of these is a random forest.
This model uses many trees and makes a prediction by averaging the prefictions of each component tree. Generally, it gives better accuracy than a single tree, and works well with default parameters.
There are models that give much better performance, but they are often sensitive to their input parameters.

We can implement this in a manner similar to the decision tree regressor. 
#+begin_src python :results verbatim
  from sklearn.ensemble import RandomForestRegressor
  from sklearn.metrics import mean_absolute_error

  forest_model=RandomForestRegressor(random_state=1)
  forest_model.fit(train_X, train_y)
  melb_preds=forest_model.predict(val_X)
  mean_absolute_error(val_y, melb_preds)

#+end_src

* Coding Exercise

#+begin_src python :results verbatim :session ML_exercise
  from sklearn.ensemble import RandomForestRegressor

  rf_model=RandomForestRegressor(random_state=1)
  rf_model.fit(train_X, train_y)

  # Calculate the MAE of our model based on the validation data
  rf_val_mae=mean_absolute_error(val_y, rf_model.predict(val_X))
  rf_val_mae
#+end_src

#+RESULTS:
: 21857.15912981083

* Machine Learning Competition

Competition - [[https://www.kaggle.com/c/home-data-for-ml-course][Link]]

#+begin_src python :results verbatim :session ML_comp
  import pandas as pd
  from sklearn.ensemble import RandomForestRegressor
  from sklearn.metrics import mean_absolute_error
  from sklearn.model_selection import train_test_split

  iowa_file_path = '/home/csj7701/roam/References/Kaggle-HousingCompetition-Train.csv'
  home_data=pd.read_csv(iowa_file_path)
  y=home_data.SalePrice

  # Create X - MODIFY ME LATER
  features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']

  # Select columns corresponding to features, preview
  X=home_data[features]
  # X.head()

  # Split into validation and training data
  train_X, val_X, train_y, val_y = train_test_split(X,y,random_state=1)

  # Define a random forest model
  rf_model=RandomForestRegressor(random_state=1)
  rf_model.fit(train_X, train_y)
  rf_val_predictions=rf_model.predict(val_X)
  rf_val_mae=mean_absolute_error(rf_val_predictions, val_y)

  rf_val_mae
#+end_src

#+RESULTS:
: 21857.15912981083

Now we train a model on /all/ the data, then run that model on the testing data to get an actual value for the competition.
#+begin_src python :results verbatim :session ML_comp
  rf_full=RandomForestRegressor(random_state=1)
  rf_full.fit(X, y)

  test_data_path='/home/csj7701/roam/References/Kaggle-HousingCompetition-Test.csv'
  test_data=pd.read_csv(test_data_path)

  test_X=test_data[features]
  test_preds=rf_full.predict(test_X)
#+end_src

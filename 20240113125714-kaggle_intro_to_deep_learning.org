:PROPERTIES:
:ID:       f040dd01-cc36-4173-aa18-4035718e7879
:END:
#+title: Kaggle: Intro to Deep Learning
#+filetags: :MachineLearning:AI:



* Neurons

Deep Learning - an approach to machine learning characterized by deep stacks of computations..
This depth is what enable deep learning models to disentangle and interpret complex and hierarchical problems.

Nerual Networks are recognized as the defining model of deep learning. They are composed of *Neurons*, where each neuron performs a single computation.
Neurons, or /units/, with one input are defined by the equation $y=wx+b$, where the input is x. Its connection to the neuron has a multiplicative weight /w/.
A neuron learns by modifying the weights attached to each neuron. /b/ represents the neurons bias - which is an additive constant that allows the neuron to modify its output independent of its input. 

We can expand our neurons to take more inputs as well, in this case we would add multiple weights and keep our individual bias. This would create an equation that looked like this: $y=w_{0}x_{0}+w_{1}x_{1}+w_{2}x_{2}+b$ where each x is our input, like before, and each w is its corresponding weight.

In python, we can use a tensorflow module called /keras/ to create deep learning models.

#+begin_src python
  from tensorflow import keras
  from tensorflow.keras import layers

  # Create a model with 1 linear unit
  model=keras.Sequential([
  layers.Dense(units=1, input_shape=[3])
  ])
#+end_src

Here, =units= defines how many outputs we want.
=input_shape= specifies the input dimensions, setting =input_shape = [3]= ensures the model will take input from 3 features.

* Coding Exercise
Set up Plotting
#+begin_src python :results verbatim :session Kaggle-DL
  import matplotlib.pyplot as plt

  plt.style.use('seaborn-whitegrid')
  plt.rc('figure', autolayout=True)
  plt.rc('axes', labelweight='bold', labelsize='large', titleweight='bold', titlesize=18, titlepad=10)
#+end_src

#+RESULTS:

#+begin_src python :results verbatim :session Kaggle-DL
  import pandas as pd

  red_wine=pd.read_csv('/home/csj7701/roam/References/Kaggle-WineData.csv')
  red_wine.head()
#+end_src

#+RESULTS:
:    fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  quality
: 0            7.4              0.70         0.00  ...       0.56      9.4        5
: 1            7.8              0.88         0.00  ...       0.68      9.8        5
: 2            7.8              0.76         0.04  ...       0.65      9.8        5
: 3           11.2              0.28         0.56  ...       0.58      9.8        6
: 4            7.4              0.70         0.00  ...       0.56      9.4        5
: 
: [5 rows x 12 columns]

Get the /shape/ - number of rows and columns
#+begin_src python :results verbatim :session Kaggle-DL
  red_wine.shape
#+end_src

#+RESULTS:
: (1599, 12)

Defining a Linear Model, where the target is quality and the remaining columns are features.
#+begin_src python :results verbatim :session Kaggle-DL
  from tensorflow import keras
  from tensorflow.keras import layers

  model=keras.Sequential([
  layers.Dense(units=1, input_shape=[11])
  ])

#+end_src

#+RESULTS:
: None

Here, we know that there are 12 total columns, and since we are looking for quality, the remaining 11 will be inputs to our model. Thus, we have to ensure that the model takes 11 inputs.


Keras represents weight with something called a *Tensor*, which is effectively an array that is treated specially by the tensorflow module. The main difference is that tensors are compatible with GPU and TPU acceleration.
A models weights are stored in its =weights= attribute as a list of tensors.
#+begin_src python :results verbatim :session Kaggle-DL
  model.weights
#+end_src

#+RESULTS:
#+begin_example
[<tf.Variable 'dense/kernel:0' shape=(11, 1) dtype=float32, numpy=
array([[ 0.26382798],
       [-0.49166387],
       [-0.38165185],
       [ 0.00448996],
       [ 0.42288262],
       [ 0.32784933],
       [-0.2744874 ],
       [-0.5374677 ],
       [-0.44155195],
       [ 0.26299298],
       [ 0.32698447]], dtype=float32)>, <tf.Variable 'dense/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]
#+end_example

Result should be:

Weights
<tf.Variable 'dense/kernel:0' shape=(11, 1) dtype=float32, numpy =
array([[-0.5920056 ],
       [-0.4777234 ],
       [-0.16399086],
       [ 0.3738181 ],
       [-0.31306443],
       [-0.3832509 ],
       [ 0.52106875],
       [ 0.14226216],
       [-0.08233064],
       [ 0.10293877],
       [-0.1660847 ]], dtype=float32)>

Bias
<tf.Variable 'dense/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>

We can see that there is one weight per input here, plus a single bias.
There doesn't seem to be a pattern to the weight value - this is because the model is untrained. An untrained model will produce random weights, and a bias of 0.0
The model /learns/ by finding better values for these weights.

** Supplemental - plotting
The examples we work with will primarily be /regression/ models - the goal is to predict some numeric target. These are essentially "curve-fitting" problems, where we try to find a curve that fits the data as closely as possible.
Linear models. like the one we created above, produce a "linear" curve (a line).
#+begin_src python :output verbatim image
  import tensorflow as tf
  from tensorflow import keras
  from tensorflow.keras import layers
  import matplotlib.pyplot as plt

  model=keras.Sequential([layers.Dense(1, input_shape=[1]),])

  x=tf.linspace(-1.0, 1.0, 100)
  y=model.predict(x)

  plt.figure(dpi=100)
  plt.plot(x,y,'k')
  plt.xlim(-1,1)
  plt.ylim(-1,1)
  plt.xlabel("Input: x")
  plt.ylabel("Target y")
  w, b = model.weights
  plt.title("Weight: {:0.2f}\nBias: {:0.2f}".format(w[0][0], b[0]))
  #plt.show()

#+end_src

#+RESULTS:
#+ATTR_LATEX: :caption \bicaption{---}
[[file:/home/csj7701/roam/Attachments/Kaggle-Deep-Learning-1.png]]
* Deep Neural Networks
We will be adding hidden layers to network, which will allow us to explore more complex relationships.

Neural Networks typically organize their neurons into *layers*.
When we collect sets of linear units which share a common set of inputs, we get a *dense layer*.

If each layer in a network performs a simple operation, as we add more and more layers, we can achieve more and more complexity.

Since dense layers are comprised of linear operations, placing two of them together with nothing in between performs no differently from a single dense layer.
Because of this, we need to add a /nonlinear/ component - this is called the *activation function*.

An activation function is simply a function that we apply to each of the layers outputs (also called its *activations*).
The most common is the /rectifier function/, =max(0,x)=.
When we attach the rectifier to a linear unit,we get something known as the rectified linear unit, or ReLU.
Thus, the rectifier function is often known as the "ReLU function".

#+ATTR_LATEX: :caption \bicaption{---}
[[file:/home/csj7701/roam/Attachments/Kaggle-Deep-Learning-2.png]]


The layers between the input and output are often called "hidden", since we can't directly see their output.
The final (output) layer is always a linear unit when we are approaching a regression problem (solving for some arbitrary number).

#+begin_src python :results verbatim

   from tensorflow import keras
   from tensorflow.keras import layers

   model=keras.Sequential([
  # Hidden ReLU Layers
  layers.Dense(units=4, activation='relu', input_shape=[2]),
  layers.Dense(units=3, activation='relu'),
  # Linear Output Layer
  layers.Dense(units=1),
  ])

#+end_src

#+RESULTS:
: None

* Coding Exercise

#+begin_src python :results verbatim :session Kaggle-DL-2
  import tensorflow as tf
  import matplotlib.pyplot as plt
  import pandas as pd
  from tensorflow import keras
  from tensorflow.keras import layers

  # plt.style.use('seaborn-whitegrid')
  plt.rc('figure', autolayout=True)
  plt.rc('axes',labelweight='bold',labelsize='large',titleweight='bold',titlesize='18',titlepad=10)

  concrete=pd.read_csv('/home/csj7701/roam/References/Kaggle-ConcreteData.csv')
  concrete.head()
#+end_src

#+RESULTS:
:    Cement  BlastFurnaceSlag  FlyAsh  ...  FineAggregate  Age  CompressiveStrength
: 0   540.0               0.0     0.0  ...          676.0   28                79.99
: 1   540.0               0.0     0.0  ...          676.0   28                61.89
: 2   332.5             142.5     0.0  ...          594.0  270                40.27
: 3   332.5             142.5     0.0  ...          594.0  365                41.05
: 4   198.6             132.4     0.0  ...          825.5  360                44.30
: 
: [5 rows x 9 columns]

We want to target this model for 'CompressiveStrength'. There are 8 other columns, so we will set our input shape to 8 when we define our model.
We will create a model with 3 hidden layers, each with 512 units and the ReLU activation. 
#+begin_src python :results verbatim :session Kaggle-DL-2
  model=keras.Sequential([
  layers.Dense(units=512, activation='relu', input_shape=[8]),
  layers.Dense(units=512, activation='relu'),
  layers.Dense(units=512, activation='relu'),
  layers.Dense(units=1)])
#+end_src

We can also define activation layers as their own layers - this is useful if we want to place anything between a layer and its activation function.
We can rewrite the block above like this:
#+begin_src python
  model=keras.Sequential([
  layers.Dense(units=512, input_shape=[8]),
  layers.Activation('relu')
  layers.Dense(units=512),
  layers.Activation('relu'),
  layers.Dense(units=512),
  layers.Activation('relu'),
  layers.Dense(units=1)])
#+end_src

** Alternatives to ReLU
There is a whole family of activation functions that are similar to ReLU. These include elu, selu, swish, and others.
Below are shown graphs of several of these, determining which function to use is largely trial and error.

ReLU:
#+ATTR_LATEX: :caption \bicaption{---}
[[file:/home/csj7701/roam/Attachments/Kaggle-relu-graph.png]]

ELU:
#+ATTR_LATEX: :caption \bicaption{---}
[[file:/home/csj7701/roam/Attachments/Kaggle-elu-graph.png]]

SeLU:
#+ATTR_LATEX: :caption \bicaption{---}
[[file:/home/csj7701/roam/Attachments/Kaggle-selu-graph.png]]

Swish:
#+ATTR_LATEX: :caption \bicaption{---}
[[file:/home/csj7701/roam/Attachments/Kaggle-swish-graph.png]]

* Stochastic Gradient Descent

When we start 'training' our models, the most important component is a set of training data.
This is the information that the model uses to 'learn' and base its weights and biases off of.
In addition, we use a *loss function* to measure the network's prediction accuracy, and an *optimizer* to tell the network /how/ to change its weights.

The loss function's primary job is to tell the network what problem to solve. It measures the disparity between the target's true value and the models prediction.
Different problems require different loss functions. In what we've done so far, and in the [[id:a9221448-bfee-4bc6-b5d4-b1aa4db97be3][Kaggle: Intro to Machine Learning]] lesson, we've used primarily *regression*, where the goal is to predict some numerical value.
A common loss function for these types of problems is *mean absolute error*, or [[file:20240113125509-kaggle_intro_to_machine_learning.org::*Model Validation][MAE]].
For each prediction the model makes, =y_pred=, the model measures the distance from the target, =y_true= using an absolute difference =abs(y_true-y_pred)=.
Besides these, other functions useful for regression include the mean-squared error (MSE) or the Huber loss functions.

We've now identified the problem for the model to solve, but we need to identify /how/ to solve it. This is what the optimizer does - adjusts the weights to minimize loss.
Almost all optimization functions used for deep learning are part of a family of functions called *Stochastic Gradient Descent*.
They train a network in steps, where one iteration consists of the following:
- Sample training data and run through model to get predictions
- Measure the loss between the predictions and the true values
- Adjust the weights in a direction that makes the loss smaller.
- Repeat until you reach an acceptable amount of loss.


Each individual sample is known as a /minibatch/, while a full iteration is called an /epoch/.
These epochs make small sequential changes - where the amount of change is determined by the /learning rate/.
A smaller learning rate means that the model will need to see more batches of training data before it accomplishes its goal.
This learning rate, combined with the size of the minibatches, are the two most influential variables in model training.

In most cases however, there is no need to adjust these in much depth. There are algorithms and functions that are designed to be adaptable and adjust both learning rate and/or batch size in order to improve performance.
=Adam= is one of these.

Adding a loss function and optimizer is relatively simple using the model's =compile= method.
#+begin_src python
  model.compile(
      optimizer="adam",
      loss="mae",
      )
#+end_src

** Example
#+begin_src python :results verbatim :session Kaggle-DL-3

  import pandas as pd
  
  red_wine=pd.read_csv('/home/csj7701/roam/References/Kaggle-WineData.csv')

  # Training and Validation Splits
  df_train=red_wine.sample(frac=0.7, random_state=0)
  df_valid=red_wine.drop(df_train.index)
  df_train.head(4)

#+end_src

#+RESULTS:
:       fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  alcohol  quality
: 1109           10.8             0.470         0.43            2.10      0.171                 27.0                  66.0  0.99820  3.17       0.76     10.8        6
: 1032            8.1             0.820         0.00            4.10      0.095                  5.0                  14.0  0.99854  3.36       0.53      9.6        5
: 1002            9.1             0.290         0.33            2.05      0.063                 13.0                  27.0  0.99516  3.26       0.84     11.7        7
: 487            10.2             0.645         0.36            1.80      0.053                  5.0                  14.0  0.99820  3.17       0.42     10.0        6

#+begin_src python :results verbatim :session Kaggle-DL-3

  # Scale to [0,1]
  max_=df_train.max(axis=0)
  min_=df_train.min(axis=0)
  df_train=(df_train-min_)/(max_-min_)
  df_valid=(df_valid-min_)/(max_-min_)

  # Split features and target
  X_train=df_train.drop('quality',axis=1)
  X_valid=df_valid.drop('quality',axis=1)
  Y_train=df_train['quality']
  Y_valid=df_valid['quality']

#+end_src

#+RESULTS:
: None

Now we need to determine the number of inputs that the network should have. To see the size of the dataset, we can run the following, then exclude our goal (quality) from the total.
#+begin_src python :results verbatim :session Kaggle-DL-3
  X_train.shape
#+end_src

#+RESULTS:
: (1119, 11)
This means that the number of inputs will be 11, since we have already excluded the 'quality' column. in the block above this one.

Now we can start building our model. We will use 3 layers with 512 neurons each.
#+begin_src python :results file :session Kaggle-DL-3

  from tensorflow import keras
  from tensorflow.keras import layers
  import matplotlib.pyplot as plt

  model=keras.Sequential([
      layers.Dense(512, activation='relu', input_shape=[11]),
      layers.Dense(512, activation='relu'),
      layers.Dense(512, activation='relu'),
      layers.Dense(1),
   ])

  model.compile(
      optimizer='adam',
      loss='mae',
  )

  history=model.fit(
      X_train, Y_train,
      validation_data=(X_valid, Y_valid),
      batch_size=256,
      epochs=10,
  )

  import pandas as pd

  history_df=pd.DataFrame(history.history)
  history_df['loss'].plot();
  plt.savefig('/home/csj7701/roam/Attachments/Kaggle-DLExample.png')
  '/home/csj7701/roam/Attachments/Kaggle-DLExample.png'
#+end_src

#+RESULTS:
[[file:/home/csj7701/roam/Attachments/Kaggle-DLExample.png]]

The plot levels out as the model runs through more epochs - when the loss curve becomes horizontal it indicates that the model has learned all it can and their is no benefit to additional epochs.

* Coding Exercise
#+begin_src python :session Kaggle-DL4

  import matplotlib.pyplot as plt
  import numpy as np
  import pandas as pd
  from sklearn.preprocessing import StandardScaler, OneHotEncoder
  from sklearn.compose import make_column_transformer, make_column_selector
  from sklearn.model_selection import train_test_split

  plt.rc('figure', autolayout=True)
  plt.rc('axes', labelweight='bold', labelsize='large',titleweight='bold',titlesize=18,titlepad=10)
  plt.rc('animation',html='html5')

  fuel=pd.read_csv('/home/csj7701/roam/References/Kaggle-FuelData.csv')

  X=fuel.copy()
  # Remove the target
  Y=X.pop('FE')

  preprocessor=make_column_transformer(
      (StandardScaler(),
       make_column_selector(dtype_include=np.number)),
      (OneHotEncoder(sparse_output=False),
       make_column_selector(dtype_include=object)),
  )

  X=preprocessor.fit_transform(X)
  Y=np.log(Y) # Log transform target instead of standardising

  input_shape=[X.shape[1]]
  input_shape
    
#+end_src

#+RESULTS:
| 50 |

#+begin_src python :results verbatim :session Kaggle-DL4

  from tensorflow import keras
  from tensorflow.keras import layers

  model=keras.Sequential([
      layers.Dense(128, activation='relu', input_shape=input_shape),
      layers.Dense(128, activation='relu'),
      layers.Dense(64, activation='relu'),
      layers.Dense(1),
      ])

  model.compile(
      optimizer='adam',
      loss='mae',
  )

  history=model.fit(
      X, Y,
      batch_size=128,
      epochs=200,
  )

#+end_src

#+RESULTS:
: None

Now we can start looking at loss curves and evaluating performance.

#+begin_src python :results file :session Kaggle-DL4

  history_df=pd.DataFrame(history.history)
  history_df.loc[5:, ['loss']].plot()
  plt.savefig('/home/csj7701/roam/Attachments/Kaggle-DLFuel.png')
  '/home/csj7701/roam/Attachments/Kaggle-DLFuel.png'

#+end_src

#+RESULTS:
[[file:/home/csj7701/roam/Attachments/Kaggle-DLFuel.png]]

Using the table below, we can experiment with different values for =learning_rate=, =batch_size=, =num_examples=

| learning_rate | batch_size | num_examples |
|          0.05 |         32 |          256 |
|          0.05 |          2 |          256 |
|          0.05 |        128 |          256 |
|          0.02 |         32 |          256 |
|           0.2 |         32 |          256 |
|           1.0 |         32 |          256 |
|           0.9 |       4096 |         8192 |
|          0.99 |       4096 |         8192 |

* Overfitting and Underfitting
As we discussed in the [[id:a9221448-bfee-4bc6-b5d4-b1aa4db97be3][Kaggle: Intro to Machine Learning]] lesson, its possible to tune a model too close to the desired output. This is called overfitting. Similarly, if a model isn't fitted close enough to the desired result it won't achieve reasonable results.

We can use the keras library to examing learning curves and see whether we are under or over fitting our model.
These learning curves are essentially a representation of loss per epoch, and we compare the curve produced by the training data to that produced by the validation data in order to see how the model actually performs.

When fitting a model, its important to understand the difference between *signal* and *noise*. The signal is the part of the data that carries actual useful information - information that can help our model make predictions. Anything else is known as noise. Ideally, a model learns from the signal and not noise, but if the model is too closely fitted to the training data it will take in more noise.
Conversely, if it is fitted too loosely, it will not take in enough signal. This is shown in the graph below.
#+ATTR_LATEX: :caption \bicaption{---}
[[file:/home/csj7701/roam/Attachments/Kaggle-Deep-Learning-3.png]]

Underfitting the training set occurs when the loss is not as low as it could be (because the model hasn't learned enough signal)
Overfitting the training set occurs when the loss is not as low as it could be (because the model has learned too much noise)

We can measure the size and complexity of patterns a model can learn through a variable called *complexity*.
In general, this is determined by the number of neurons and how they are connected. If a network is underfitting, try increasing its capacity.
You can do this by making it /wider/ (add more units to existing layers) or deeper (adding more layers).
Wider networks generally learn linear relationships more easily, while deeper networks tend to perform better on non-linear ones.

Sometimes, a model might learn noise to readily during training - this will result in an increase in loss in the training curve. To fix this, we can use a process called *Early Stopping*, where we end the training wherever the validation loss stops decreasing. This can help prevent overfitting.
We can implement this early stop using a function known as a callback

#+BEGIN_SRC python :results none
  from tensorflow.keras.callbacks import EarlyStopping

  early_stopping=EarlyStopping(
      min_delta=0.001, # minimum amount of change to count as an improvement
      patience=20, # how many epochs to wait before stopping
      restore_best_weights=True,
  )
#+END_SRC

We then add this callback function as an argument to the fit function, formatting our callbacks as a list

#+begin_src python :results none

  model.fit(
      ...
      epochs=500,
      callbacks=[early_stopping],
  )

#+end_src

When we use the early stop function, typically we want to choose a number of epochs larger than what we need.

* Coding exercise
#+begin_src python :results verbatim :session Kaggle-Dl-Spot
  import matplotlib.pyplot as plt
  import pandas as pd
  from sklearn.preprocessing import StandardScaler, OneHotEncoder
  from sklearn.compose import make_column_transformer
  from sklearn.model_selection import GroupShuffleSplit
  from tensorflow import keras
  from tensorflow.keras import layers, callbacks

  plt.rc('figure', autolayout=True)
  plt.rc('axes', labelweight='bold', labelsize='large', titleweight='bold', titlesize=18, titlepad=10)

  spotify=pd.read_csv('/home/csj7701/roam/References/Kaggle-SpotifyData.csv')

  X=spotify.copy().dropna()
  Y=X.pop('track_popularity')
  artists=X['track_artist']

  features_num=['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms']
  features_cat=['playlist_genre']

  preprocessor=make_column_transformer(
      (StandardScaler(), features_num),
      (OneHotEncoder(), features_cat),
      )

  # We use a grouped split here to keep artist songs in one group or another
  def group_split(X, Y, group, train_size=0.75):
      splitter= GroupShuffleSplit(train_size=train_size)
      train, test=next(splitter.split(X,Y,groups=group))
      return (X.iloc[train], X.iloc[test], Y.iloc[train], Y.iloc[test])

  X_train, X_valid, Y_train, Y_valid=group_split(X,Y,artists)

  X_train=preprocessor.fit_transform(X_train)
  X_valid=preprocessor.transform(X_valid)
  Y_train=Y_train/100 # Popularity is on a 0-100 scale. Rescales to 0-1
  Y_valid=Y_valid/100

  input_shape=[X_train.shape[1]]
  input_shape

#+end_src

#+RESULTS:
: [18]


#+begin_src python :results verbatim :session Kaggle-Dl-Spot
  model=keras.Sequential([
      layers.Dense(1, input_shape=input_shape),
      ])
  model.compile(
      optimizer='adam',
      loss='mae',
      )
  history=model.fit(
      X_train, Y_train,
      validation_data=(X_valid, Y_valid),
      batch_size=512,
      epochs=50,
      verbose=0,
      )
  history_df=pd.DataFrame(history.history)
  history_df.loc[0:, ['loss', 'val_loss']].plot()

  history_df['val_loss'].min()
#+end_src

#+RESULTS:
: 0.19785484671592712

We get the following graph from this model:
#+ATTR_LATEX: :caption \bicaption{---}
[[file:/home/csj7701/roam/Attachments/Kaggle-Deep-Learning-4.png]]

If we zoom in we see:

#+ATTR_LATEX: :caption \bicaption{---}
[[file:/home/csj7701/roam/Attachments/Kaggle-Deep-Learning-5.png]]

The gap here is quite small, and validation loss never increases, so its likely that the model is underfitting.
Next, we will increase the models capacity to see if we can improve this performance.

#+begin_src python :results verbatim :session Kaggle-Dl-Spot

  model=keras.Sequential([
      layers.Dense(128, activation='relu', input_shape=input_shape),
      layers.Dense(64, activation='relu'),
      layers.Dense(1)
      ])
  model.compile(
      optimizer='adam',
      loss='mae',
      )
  history=model.fit(
      X_train, Y_train,
      validation_data=(X_valid, Y_valid),
      batch_size=512,
      epochs=50,
      )
  history_df=pd.DataFrame(history.history)
  history_df.loc[:, ['loss', 'val_loss']].plot()
  history_df['val_loss'].min()

#+end_src

#+RESULTS:
: 0.1985759139060974

This model produces the following graph:
#+ATTR_LATEX: :caption \bicaption{---}
[[file:/home/csj7701/roam/Attachments/Kaggle-Deep-Learning-6.png]]

This shows the validation loss rising early, while training loss continues to decrease; which indicates that the model has begun to overfit. To prevent this, we must either reduce the number of units, or try early stopping. We will try early stopping.

#+begin_src python :results verbatim :session Kaggle-Dl-Spot

  early_stopping=callbacks.EarlyStopping(
      patience=5,
      min_delta=0.001,
      restore_best_weights=True,
      )

  model=keras.Sequential([
      layers.Dense(128, activation='relu', input_shape=input_shape),
      layers.Dense(64, activation='relu'),
      layers.Dense(1)])

  model.compile(
      optimizer='adam',
      loss='mae')

  history=model.fit(
      X_train, Y_train, validation_data=(X_valid, Y_valid),
      batch_size=512, epochs=50, callbacks=[early_stopping])

  history_df=pd.DataFrame(history.history)
  history_df.loc[:, ['loss', 'val_loss']].plot()
  history_df['val_loss'].min()
#+end_src

#+RESULTS:
: 0.1996046006679535

This trial returns:

#+ATTR_LATEX: :caption \bicaption{---}
[[file:/home/csj7701/roam/Attachments/Kaggle-Deep-Learning-7.png]]

This is an improvement . We can see that the model stops once it began overfitting. 

* Dropout and Batch Normalization
So far, we have used primarily /Dense Layers/. There are other kinds however.
The first of these is known a the *Dropout Layer*.
We use this layer to help correct overfitting. The dropout layer will randomly /drop/ some fraction of a layer's input units on every step of training.
This serves to vary the training data and make it more difficult for the model to adhere to closely to any incidental patterns in the training data that might not be indicative of the actual data.
Similar to adding Dense layers, we specify Dropout layers inside our model definition immediately before the layer that we want the drop to apply to. These layers take a /rate/ argument, that defines what percentage of the input to remove.

Another special layer is the batch normalization, or 'batchnorm' layer. This is used to help correct data that is slow or unstable.
Its generally helpful to apply the same scale to all of the data that we feed into a model.
_This is because weight shifts proportionally to the size of an inputs activation. If there are differences in activation size, the network can become unstable as it trains._
If we normalize the data that we input into the network, it may make more sense to normalize inside of the network. This is what the batch normalization layer is for.
The batch normalization layer takes each batch and normalizes according to mean and standard deviation, scaling this data with 2 parameters that are each 'trainable'.
Typically, this is added in order to help with the optimization process; although it can help with prediction.
Batch normalization layers can be added at almost any point within a network; this includes after a layer, or between a layer and its activation function.
It can also be added as the first layer of the network where it can replace other forms of input processors.

** Example
#+begin_src python :results none

  from tensorflow import keras
  from tensorflow.keras import layers

  model=keras.Sequential([
      layers.Dense(1024, activation='relu', input_shape=[11]),
      layers.Dropout(0.3),
      layers.BatchNormalization(),
      layers.Dense(1024, activation='relu'),
      layers.Dropout(0.3),
      layers.BatchNormalization(),
      layers.Dense(1024, activation='relu'),
      layers.Dropout(0.3),
      layers.BatchNormalization(),
      layers.Dense(1),
      ])

  model.compile(
      optimizer='adam',
      loss='mae',
      )

  history=model.fit(
      X_train, Y_train,
      validation_data=(X_valid, Y_valid),
      batch_size=256,
      epochs=100,
      verbose=0,
      )

#+end_src

* Coding Exercise

We use the same session as the last exercise, working with spotify data.

#+begin_src python :results verbatim :session Kaggle-Dl-Spot

  model=keras.Sequential([
      layers.Dense(128, activation='relu', input_shape=input_shape),
      layers.Dropout(0.3),
      layers.Dense(64, activation='relu'),
      layers.Dropout(0.3),
      layers.Dense(1)])

#+end_src

#+RESULTS:
: None

Now we compile and train the model, comparing it to the previous results in order to check the impact of our new dropout layers.

#+begin_src python :results verbatim :session Kaggle-Dl-Spot

  model.compile(
      optimizer='adam',
      loss='mae',
      )
  history=model.fit(
      X_train, Y_train,
      validation_data=(X_valid, Y_valid),
      batch_size=512,
      epochs=50,
      verbose=0,
      )
  history_df=pd.DataFrame(history.history)
  history_df.loc[:, ['loss', 'val_loss']].plot()
  "Minimum Validation Loss: {:0.4f}".format(history_df['val_loss'].min())

#+end_src

#+RESULTS:
: Minimum Validation Loss: 0.1942

#+ATTR_LATEX: :caption \bicaption{---}
[[file:/home/csj7701/roam/Attachments/Kaggle-Deep-Learning-8.png]]

Here, we see that validation loss remains near a constant minimum, even though training loss continues to decrease. This indicates that adding dropout layers did seem to help prevent overfitting this time, which previousy occured around epoch 5.

Now we switch gears to examine batch normalization
#+begin_src python :results verbatim :session Kaggle-Dl-Spot

  import pandas as pd

  concrete=pd.read_csv('/home/csj7701/roam/References/Kaggle-ConcreteData.csv')
  df=concrete.copy()
    
  df_train=df.sample(frac=0.7, random_state=0)
  df_valid=df.drop(df_train.index)

  X_train=df_train.drop('CompressiveStrength', axis=1)
  X_valid=df_valid.drop('CompressiveStrength', axis=1)
  Y_train=df_train['CompressiveStrength']
  Y_valid=df_valid['CompressiveStrength']

  input_shape=[X_train.shape[1]]

  model=keras.Sequential([
      layers.Dense(512, activation='relu', input_shape=input_shape),
      layers.Dense(512, activation='relu'),
      layers.Dense(512, activation='relu'),
      layers.Dense(1),
      ])
  model.compile(
      optimizer='sgd', # SGD is more sensitive to changes in scale
      loss='mae',
      metrics=['mae'],
      )
  history=model.fit(
      X_train, Y_train,
      validation_data=(X_valid, Y_valid),
      batch_size=64,
      epochs=100,
      verbose=0,
      )
  history_df=pd.DataFrame(history.history)
  history_df.loc[0:, ['loss', 'val_loss']].plot()
  "Minimum Validation Loss: {:0.4f}".format(history_df['val_loss'].min())
#+end_src

#+RESULTS:
: Minimum Validation Loss: nan

We got an invalid result - we can use normalization to help correct this.

#+begin_src python :results verbatim :session Kaggle-Dl-Spot

  model=keras.Sequential([
      layers.BatchNormalization(),
      layers.Dense(512, activation='relu', input_shape=input_shape),
      layers.BatchNormalization(),
      layers.Dense(512, activation='relu'),
      layers.BatchNormalization(),
      layers.Dense(512, activation='relu'),
      layers.BatchNormalization(),
      layers.Dense(1),
      ])
  model.compile(
      optimizer='sgd',
      loss='mae',
      metrics=['mae'])
  EPOCHS=100
  history=model.fit(
      X_train, Y_train,
      validation_data=(X_valid, Y_valid),
      batch_size=64,
      epochs=EPOCHS,
      verbose=0)
  history_df=pd.DataFrame(history.history)
  history_df.loc[0:, ['loss', 'val_loss']].plot()
  "Minimum Validation Loss: {:0.4f}".format(history_df['val_loss'].min())

#+end_src

#+RESULTS:
: Minimum Validation Loss: 3.9999

#+ATTR_LATEX: :caption \bicaption{---}
[[file:/home/csj7701/roam/Attachments/Kaggle-Deep-Learning-9.png]]

Here, we can see that adding batch normalization was a significant improvement on the first attempt (We actually got a result). 

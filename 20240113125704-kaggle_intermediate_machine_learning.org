:PROPERTIES:
:ID:       34108a3d-efff-43a3-9bab-e9b5fbb0fab8
:END:
#+title: Kaggle: Intermediate Machine Learning

* Code Exercise

#+begin_src python :results verbatim :session Kaggle-IML

  import os
  if not os.path.exists("/home/csj7701/roam/References/Kaggle-Train.csv"):
      print("File not found")

  import pandas as pd
  from sklearn.model_selection import train_test_split

  X_full=pd.read_csv("/home/csj7701/roam/References/Kaggle-Train.csv")
  X_test_full=pd.read_csv("/home/csj7701/roam/References/Kaggle-Test.csv")

  y=X_full.SalePrice
  features=['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']
  X=X_full[features].copy()
  X_test=X_test_full[features].copy()

  X_train, X_valid, y_train, y_valid=train_test_split(X,y,train_size=0.8, test_size=0.2,random_state=0)

  X_train.head()

#+end_src

#+RESULTS:
:      LotArea  YearBuilt  1stFlrSF  2ndFlrSF  FullBath  BedroomAbvGr  TotRmsAbvGrd
: 618    11694       2007      1828         0         2             3             9
: 870     6600       1962       894         0         1             2             5
: 92     13360       1921       964         0         1             2             5
: 817    13265       2002      1689         0         2             3             7
: 302    13704       2001      1541         0         2             3             6

#+begin_src python :results verbatim :session Kaggle-IML

  from sklearn.ensemble import RandomForestRegressor

  model_1=RandomForestRegressor(n_estimators=50, random_state=0)
  model_2=RandomForestRegressor(n_estimators=100, random_state=0)
  model_3=RandomForestRegressor(n_estimators=100, criterion='absolute_error', random_state=0)
  model_4=RandomForestRegressor(n_estimators=200, min_samples_split=20, random_state=0)
  model_5=RandomForestRegressor(n_estimators=100, max_depth=7, random_state=0)

  models=[model_1, model_2, model_3, model_4, model_5]
#+end_src

#+RESULTS:
: None

#+begin_src python :results verbatim :session Kaggle-IML

  from sklearn.metrics import mean_absolute_error

  def score_model(model, X_t=X_train, X_v=X_valid, y_t=y_train, y_v=y_valid):
      model.fit(X_t, y_t)
      preds=model.predict(X_v)
      return mean_absolute_error(y_v, preds)

  result=""
  for i in range(0, len(models)):
      mae=score_model(models[i])
      new_result="Model {} MAE: {}\n".format(i+1, mae)
      result+=new_result
  result

#+end_src

#+RESULTS:
: Model 1 MAE: 24015.492818003917
: Model 2 MAE: 23740.979228636657
: Model 3 MAE: 23528.78421232877
: Model 4 MAE: 23996.676789668687
: Model 5 MAE: 23706.672864217904


Here, we can see that the best performing model is model_3 with the lowest MAE.

#+begin_src python :results verbatim :session Kaggle-IML

  my_model=model_3

  my_model.fit(X,y)

  preds_test=my_model.predict(X_test)
  output=pd.DataFrame({'Id':X_test.index,'SalePrice':preds_test})
  output

#+end_src

#+RESULTS:
#+begin_example
        Id  SalePrice
0        0  119433.08
1        1  158367.50
2        2  185351.21
3        3  178343.12
4        4  192898.29
...    ...        ...
1454  1454   86155.00
1455  1455   89050.00
1456  1456  156296.92
1457  1457  132232.50
1458  1458  230870.60

[1459 rows x 2 columns]
#+end_example

* Handling Missing Values

Most machine learning libraries will throw an error if you try to build a model with missing values.

There are typically 3 options to handle these missing values:
- Drop columns with missing values
  This removes any data column that is missing information. This could result in the model losing significant amounts of information however, so it should not be the first choice.
- Imputation
  This is a better option than dropping columns. Imputation fills in missing values with a number. This likely won't be 100% accurate, but it will allow the model to retain much more information than it would if we removed columns.
- Extension to imputation
  When we use imputation, there is always the chance that the data we fill in to the missing slot will differ from what /should/ be there. The model would likely improve by taking into consideration whether a value was imputed, or whether it was part of the original dataset. Therefore, we can add a new column that contains boolean values indicating whether a value was imputed or not.


* Code Exercise
#+begin_src python :results verbatim :session Kaggle-IML-2

  import pandas as pd
  from sklearn.model_selection import train_test_split

  X_full=pd.read_csv('/home/csj7701/roam/References/Kaggle-Train.csv', index_col='Id')
  X_test_full=pd.read_csv('/home/csj7701/roam/References/Kaggle-Test.csv', index_col='Id')

  X_full.dropna(axis=0, subset=['SalePrice'], inplace=True)
  Y=X_full.SalePrice
  X_full.drop(['SalePrice'], axis=1, inplace=True)

  X=X_full.select_dtypes(exclude=['object'])
  X_test=X_test_full.select_dtypes(exclude=['object'])

  X_train, X_valid, Y_train, Y_valid=train_test_split(X,Y,train_size=0.8, test_size=0.2, random_state=0)

  X_train.shape
#+end_src

#+RESULTS:
: (1168, 36)


Now we can see the number of missing values in each column of the training data.
#+begin_src python :results verbatim :session Kaggle-IML-2

  missing_val_count_by_column=(X_train.isnull().sum())
  missing_val_count_by_column[missing_val_count_by_column > 0]

#+end_src

#+RESULTS:
: LotFrontage    212
: MasVnrArea       6
: GarageYrBlt     58
: dtype: int64


We can see that we have 1168 rows in our dataset.
3 Columns in our dataset are missing values, with a total of 276 missing values.
The column with the /most/ missing values is =LotFrontage=, missing 212 of its 1168 values. This is around 20%, which would indicate that dropping columns will not be particularly effective, since there is still a good deal of useful information in the offending columns.

We will now use a =score_dataset= function to evaluate different datasets based on the MAE from a forest regression model.

#+begin_src python :results verbatim :session Kaggle-IML-2

  from sklearn.ensemble import RandomForestRegressor
  from sklearn.metrics import mean_absolute_error

  def score_dataset(X_train, X_valid, Y_train, Y_valid):
      model=RandomForestRegressor(n_estimators=100, random_state=0)
      model.fit(X_train, Y_train)
      preds=model.predict(X_valid)
      return mean_absolute_error(Y_valid, preds)

#+end_src

#+RESULTS:

Lets check the MAE from dropping values
#+begin_src python :results verbatim :session Kaggle-IML-2

  cols_with_missing_values=[col for col in X_train.columns if X_train[col].isnull().any()]

  reduced_X_train=X_train.drop(cols_with_missing_values, axis=1)
  reduced_X_valid=X_valid.drop(cols_with_missing_values, axis=1)

  string=(f"MAE (Drop columns with missing values):\n{score_dataset(reduced_X_train, reduced_X_valid, Y_train, Y_valid)}")

  string
#+end_src

#+RESULTS:
: MAE (Drop columns with missing values):
: 17837.82570776256

Now lets check Imputation
#+begin_src python :results verbatim :session Kaggle-IML-2

  from sklearn.impute import SimpleImputer

  my_imputer=SimpleImputer()
  imputed_X_train=pd.DataFrame(my_imputer.fit_transform(X_train))
  imputed_X_valid=pd.DataFrame(my_imputer.fit_transform(X_valid))

  # Imputation removed some column names. We need to put them back.
  imputed_X_train.columns=X_train.columns
  imputed_X_valid.columns=X_valid.columns

  string=(f"MAE (Imputation):\n{score_dataset(imputed_X_train, imputed_X_valid, Y_train, Y_valid)})")
  string

#+end_src

#+RESULTS:
: MAE (Imputation):
: 18056.85163242009)


We see here that imputation performed slightly worse than dropping values. This is surprising, given how few missing values there were compared to the actual size of the dataset. We can attribute this to a few things. "Noise" in the dataset - not clear on that this exactly refers to. Or, (more likely) the fact that imputation might not be a great fit for this dataset. We might have fared better by looking for a common or repeated value in the data and inserting that, or simply inserting 0, etc. Imputation just inserts the mean value, so that may not make the most sense. 





:PROPERTIES:
:ID:       34108a3d-efff-43a3-9bab-e9b5fbb0fab8
:END:
#+title: Kaggle: Intermediate Machine Learning

* Code Exercise

#+begin_src python :results verbatim :session Kaggle-IML

  import os
  if not os.path.exists("/home/csj7701/roam/References/Kaggle-Train.csv"):
      print("File not found")

  import pandas as pd
  from sklearn.model_selection import train_test_split

  X_full=pd.read_csv("/home/csj7701/roam/References/Kaggle-Train.csv")
  X_test_full=pd.read_csv("/home/csj7701/roam/References/Kaggle-Test.csv")

  y=X_full.SalePrice
  features=['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']
  X=X_full[features].copy()
  X_test=X_test_full[features].copy()

  X_train, X_valid, y_train, y_valid=train_test_split(X,y,train_size=0.8, test_size=0.2,random_state=0)

  X_train.head()

#+end_src

#+RESULTS:
:      LotArea  YearBuilt  1stFlrSF  2ndFlrSF  FullBath  BedroomAbvGr  TotRmsAbvGrd
: 618    11694       2007      1828         0         2             3             9
: 870     6600       1962       894         0         1             2             5
: 92     13360       1921       964         0         1             2             5
: 817    13265       2002      1689         0         2             3             7
: 302    13704       2001      1541         0         2             3             6

#+begin_src python :results verbatim :session Kaggle-IML

  from sklearn.ensemble import RandomForestRegressor

  model_1=RandomForestRegressor(n_estimators=50, random_state=0)
  model_2=RandomForestRegressor(n_estimators=100, random_state=0)
  model_3=RandomForestRegressor(n_estimators=100, criterion='absolute_error', random_state=0)
  model_4=RandomForestRegressor(n_estimators=200, min_samples_split=20, random_state=0)
  model_5=RandomForestRegressor(n_estimators=100, max_depth=7, random_state=0)

  models=[model_1, model_2, model_3, model_4, model_5]
#+end_src

#+RESULTS:
: None

#+begin_src python :results verbatim :session Kaggle-IML

  from sklearn.metrics import mean_absolute_error

  def score_model(model, X_t=X_train, X_v=X_valid, y_t=y_train, y_v=y_valid):
      model.fit(X_t, y_t)
      preds=model.predict(X_v)
      return mean_absolute_error(y_v, preds)

  result=""
  for i in range(0, len(models)):
      mae=score_model(models[i])
      new_result="Model {} MAE: {}\n".format(i+1, mae)
      result+=new_result
  result

#+end_src

#+RESULTS:
: Model 1 MAE: 24015.492818003917
: Model 2 MAE: 23740.979228636657
: Model 3 MAE: 23528.78421232877
: Model 4 MAE: 23996.676789668687
: Model 5 MAE: 23706.672864217904


Here, we can see that the best performing model is model_3 with the lowest MAE.

#+begin_src python :results verbatim :session Kaggle-IML

  my_model=model_3

  my_model.fit(X,y)

  preds_test=my_model.predict(X_test)
  output=pd.DataFrame({'Id':X_test.index,'SalePrice':preds_test})
  output

#+end_src

#+RESULTS:
#+begin_example
        Id  SalePrice
0        0  119433.08
1        1  158367.50
2        2  185351.21
3        3  178343.12
4        4  192898.29
...    ...        ...
1454  1454   86155.00
1455  1455   89050.00
1456  1456  156296.92
1457  1457  132232.50
1458  1458  230870.60

[1459 rows x 2 columns]
#+end_example

* Handling Missing Values

Most machine learning libraries will throw an error if you try to build a model with missing values.

There are typically 3 options to handle these missing values:
- Drop columns with missing values
  This removes any data column that is missing information. This could result in the model losing significant amounts of information however, so it should not be the first choice.
- Imputation
  This is a better option than dropping columns. Imputation fills in missing values with a number. This likely won't be 100% accurate, but it will allow the model to retain much more information than it would if we removed columns.
- Extension to imputation
  When we use imputation, there is always the chance that the data we fill in to the missing slot will differ from what /should/ be there. The model would likely improve by taking into consideration whether a value was imputed, or whether it was part of the original dataset. Therefore, we can add a new column that contains boolean values indicating whether a value was imputed or not.


* Code Exercise
#+begin_src python :results verbatim :session Kaggle-IML-2

  import pandas as pd
  from sklearn.model_selection import train_test_split

  X_full=pd.read_csv('/home/csj7701/roam/References/Kaggle-Train.csv', index_col='Id')
  X_test_full=pd.read_csv('/home/csj7701/roam/References/Kaggle-Test.csv', index_col='Id')

  X_full.dropna(axis=0, subset=['SalePrice'], inplace=True)
  Y=X_full.SalePrice
  X_full.drop(['SalePrice'], axis=1, inplace=True)

  X=X_full.select_dtypes(exclude=['object'])
  X_test=X_test_full.select_dtypes(exclude=['object'])

  X_train, X_valid, Y_train, Y_valid=train_test_split(X,Y,train_size=0.8, test_size=0.2, random_state=0)

  X_train.shape
#+end_src

#+RESULTS:
: (1168, 36)


Now we can see the number of missing values in each column of the training data.
#+begin_src python :results verbatim :session Kaggle-IML-2

  missing_val_count_by_column=(X_train.isnull().sum())
  missing_val_count_by_column[missing_val_count_by_column > 0]

#+end_src

#+RESULTS:
: LotFrontage    212
: MasVnrArea       6
: GarageYrBlt     58
: dtype: int64


We can see that we have 1168 rows in our dataset.
3 Columns in our dataset are missing values, with a total of 276 missing values.
The column with the /most/ missing values is =LotFrontage=, missing 212 of its 1168 values. This is around 20%, which would indicate that dropping columns will not be particularly effective, since there is still a good deal of useful information in the offending columns.

We will now use a =score_dataset= function to evaluate different datasets based on the MAE from a forest regression model.

#+begin_src python :results verbatim :session Kaggle-IML-2

  from sklearn.ensemble import RandomForestRegressor
  from sklearn.metrics import mean_absolute_error

  def score_dataset(X_train, X_valid, Y_train, Y_valid):
      model=RandomForestRegressor(n_estimators=100, random_state=0)
      model.fit(X_train, Y_train)
      preds=model.predict(X_valid)
      return mean_absolute_error(Y_valid, preds)

#+end_src

#+RESULTS:

Lets check the MAE from dropping values
#+begin_src python :results verbatim :session Kaggle-IML-2

  cols_with_missing_values=[col for col in X_train.columns if X_train[col].isnull().any()]

  reduced_X_train=X_train.drop(cols_with_missing_values, axis=1)
  reduced_X_valid=X_valid.drop(cols_with_missing_values, axis=1)

  string=(f"MAE (Drop columns with missing values):\n{score_dataset(reduced_X_train, reduced_X_valid, Y_train, Y_valid)}")

  string
#+end_src

#+RESULTS:
: MAE (Drop columns with missing values):
: 17837.82570776256

Now lets check Imputation
#+begin_src python :results verbatim :session Kaggle-IML-2

  from sklearn.impute import SimpleImputer

  my_imputer=SimpleImputer()
  imputed_X_train=pd.DataFrame(my_imputer.fit_transform(X_train))
  imputed_X_valid=pd.DataFrame(my_imputer.fit_transform(X_valid))

  # Imputation removed some column names. We need to put them back.
  imputed_X_train.columns=X_train.columns
  imputed_X_valid.columns=X_valid.columns

  string=(f"MAE (Imputation):\n{score_dataset(imputed_X_train, imputed_X_valid, Y_train, Y_valid)})")
  string

#+end_src

#+RESULTS:
: MAE (Imputation):
: 18056.85163242009)


We see here that imputation performed slightly worse than dropping values. This is surprising, given how few missing values there were compared to the actual size of the dataset. We can attribute this to a few things. "Noise" in the dataset - not clear on that this exactly refers to. Or, (more likely) the fact that imputation might not be a great fit for this dataset. We might have fared better by looking for a common or repeated value in the data and inserting that, or simply inserting 0, etc. Imputation just inserts the mean value, so that may not make the most sense. 


* Categorical Variables

Categorical variables take a limited number of values.
This could include examples like multiple choice test questions, dropdown menus, etc.
This could also include values which are not limited, but which can be categorized into a finite number of equivalent values. An example of this is, in a survey of car owners, the brand of their car.

There are 3 general approaches to categorical variables:
- Drop Categorical Variables
  This is the easiest. In this situation, we simply remove any categorical variables from the dataset. This only works well if the columns with the categorical data were not useful.

- Ordinal Encoding
  Ordinal encoding assigns each unique categorical value a unique integer (Every day=3, Never=0, Rarely=1, etc)
  This assumes a distinct order to the values. Not all categorical values have an order to them, but those that do are known as "ordinal values"

- One Hot Encoding
  This method creates a new column for each value the categorical data can take on, assigning a 1 or 0 based on the value of the data.
  For example, if a =color= column has categorical values =red=, =green=, and =orange=; one-hot encoding would create 3 new columns, "red", "green", and "orange"; assigning a 1 in the orange column to any entry that had "orange" in the color column.
  One Hot Encoding does /not/ assume an order, and we refer to variables with no intrisic ranking as "nominal variables". This typically does not work well if the nominal variable can take on a wide range of values.


* Code Exercise

#+begin_src python :results verbatim :session Kaggle-IML-3

  import pandas as pd
  from sklearn.model_selection import train_test_split
  # Read the data
  X = pd.read_csv('/home/csj7701/roam/References/Kaggle-Train.csv', index_col='Id') 
  X_test = pd.read_csv('/home/csj7701/roam/References/Kaggle-Test.csv', index_col='Id')

  # Remove rows with missing target, separate target from predictors
  X.dropna(axis=0, subset=['SalePrice'], inplace=True)
  y = X.SalePrice
  X.drop(['SalePrice'], axis=1, inplace=True)

  # To keep things simple, we'll drop columns with missing values
  cols_with_missing = [col for col in X.columns if X[col].isnull().any()] 
  X.drop(cols_with_missing, axis=1, inplace=True)
  X_test.drop(cols_with_missing, axis=1, inplace=True)

  # Break off validation set from training data
  X_train, X_valid, y_train, y_valid = train_test_split(X, y,
      train_size=0.8, test_size=0.2,
      random_state=0)

  X_train.head()
#+end_src

#+RESULTS:
:      MSSubClass MSZoning  LotArea Street LotShape LandContour Utilities LotConfig  ... 3SsnPorch ScreenPorch PoolArea MiscVal MoSold YrSold  SaleType  SaleCondition
: Id                                                                                 ...                                                                              
: 619          20       RL    11694   Pave      Reg         Lvl    AllPub    Inside  ...         0         260        0       0      7   2007       New        Partial
: 871          20       RL     6600   Pave      Reg         Lvl    AllPub    Inside  ...         0           0        0       0      8   2009        WD         Normal
: 93           30       RL    13360   Pave      IR1         HLS    AllPub    Inside  ...         0           0        0       0      8   2009        WD         Normal
: 818          20       RL    13265   Pave      IR1         Lvl    AllPub   CulDSac  ...         0           0        0       0      7   2008        WD         Normal
: 303          20       RL    13704   Pave      IR1         Lvl    AllPub    Corner  ...         0           0        0       0      1   2006        WD         Normal
: 
: [5 rows x 60 columns]


This dataset has both numerical and categorical variables. We will need to encode the data before we can create a model.

#+begin_src python :results verbatim :session Kaggle-IML-3
  from sklearn.ensemble import RandomForestRegressor
  from sklearn.metrics import mean_absolute_error

  # function for comparing different approaches
  def score_dataset(X_train, X_valid, y_train, y_valid):
      model = RandomForestRegressor(n_estimators=100, random_state=0)
      model.fit(X_train, y_train)
      preds = model.predict(X_valid)
      return mean_absolute_error(y_valid, preds)

#+end_src

#+RESULTS:

We will start by dropping the offending columns

#+begin_src python :results verbatim :session Kaggle-IML-3

  drop_X_train=X_train.select_dtypes(exclude=['object'])
  drop_X_valid=X_valid.select_dtypes(exclude=['object'])

  string=(f"MAE from Approach 1 (Drop categorical vars): {score_dataset(drop_X_train, drop_X_valid, y_train, y_valid)}")
  string

#+end_src

#+RESULTS:
: MAE from Approach 1 (Drop categorical vars): 17837.82570776256


Now before we move on, lets examine the dataset a little more closely.
#+begin_src python :session Kaggle-IML-3 :results verbatim

  string=(f"Unique values in 'Condition2' column in training data:{X_train['Condition2'].unique()}\nUnique values in 'Condition2' column in validation data:{X_valid['Condition2'].unique()}")

  string

#+end_src

#+RESULTS:
: Unique values in 'Condition2' column in training data:['Norm' 'PosA' 'Feedr' 'PosN' 'Artery' 'RRAe']
: Unique values in 'Condition2' column in validation data:['Norm' 'RRAn' 'RRNn' 'Artery' 'Feedr' 'PosN']

We can see that there are columns in the validation data that do not appear in the training data.
If we try to encode our training data, we will get an error because the encoder will not have values to assign these categories.

This is a common problem with real-world data. The simplest solution is to simply drop any columns that appear in the validation data and not in the training data.

#+begin_src python :results verbatim :session Kaggle-IML-3
  # Categorical columns in the training data
  object_cols = [col for col in X_train.columns if X_train[col].dtype == "object"]

  # Columns that can be safely ordinal encoded
  good_label_cols = [col for col in object_cols if 
                     set(X_valid[col]).issubset(set(X_train[col]))]
        
  # Problematic columns that will be dropped from the dataset
  bad_label_cols = list(set(object_cols)-set(good_label_cols))
        
  string=(f"Categorical columns that will be ordinal encoded:{good_label_cols}\nCategorical columns that will be dropped from the dataset:{bad_label_cols}")

  string

#+end_src

#+RESULTS:
: Categorical columns that will be ordinal encoded:['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'BldgType', 'HouseStyle', 'RoofStyle', 'Exterior1st', 'Exterior2nd', 'ExterQual', 'ExterCond', 'Foundation', 'Heating', 'HeatingQC', 'CentralAir', 'KitchenQual', 'PavedDrive', 'SaleType', 'SaleCondition']
: Categorical columns that will be dropped from the dataset:['RoofMatl', 'Condition2', 'Functional']


Now we use ordinal encoding to encode our data.

#+begin_src python :results verbatim :session Kaggle-IML-3
  from sklearn.preprocessing import OrdinalEncoder

  # Drop categorical columns that will not be encoded
  label_X_train = X_train.drop(bad_label_cols, axis=1)
  label_X_valid = X_valid.drop(bad_label_cols, axis=1)

  # Apply ordinal encoder
  ordinal_encoder = OrdinalEncoder()
  label_X_train[good_label_cols] = ordinal_encoder.fit_transform(X_train[good_label_cols])
  label_X_valid[good_label_cols] = ordinal_encoder.transform(X_valid[good_label_cols])

#+end_src

#+RESULTS:
